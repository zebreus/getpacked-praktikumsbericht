Praxisbericht
============

Einleitung
----------
In meiner Praxisphase bei der getpacked GmbH habe ich in den letzten 3 Monaten viel Erfahrung im Bereich der Softwareentwicklung sammeln. Ich habe die getpacked GmbH fÃ¼r mein Praktikum gewÃ¤hlt, da ich vorher hauptsÃ¤chlich mit Systemprogrammiersprachen gearbeitet habe und nun auch einmal Erfahrung mit den Technologien moderner Webentwicklung sammeln wollte. Meine Aufgabe wÃ¤hrend der Praxisphase waren unter anderem die EinfÃ¼hrung einer Continuous Integration/ Continuous Delivery Infrastruktur und das Erarbeiten und Umsetzen von MaÃŸnahmen zur Verbesserung der QualitÃ¤t des Quellcodes. Ausserdem konnte ich wÃ¤hrend meines Praktikums viel Ã¼ber das Arbeiten in einem agilen Team lernen.

Die Suche nach einem Praktikumsplatz habe ich lange herausgezÃ¶gert, dann aber als ich mal angefangen hatte zu suchen Ã¼ber LinkedIn schnell einen Praktikumsplatz gefunden. Als hilfreiche Strategie hat sich herausgestellt, an Firmen mit interessanten offenen Stellen Bewerbungen zu schicken und die Firmen dann davon zu Ã¼berzeugen, dass sie eigentlih keinen Angestellten, sondern nur einen Praktikanten suchen. Ausserdem ermÃ¶glicht LinkedIn das Bewerben nur mit Lebenslauf, was sehr angenehm ist, da fÃ¼r mich das Verfassen eines guten Anschreibens der unangenehmste Teil des Bewerbungsprozesses war.

Ich habe mir von dem Praktikum hauptsÃ¤chlich erhofft, Einblick darÃ¼ber, wie Webentwicklung mit einem modernen Technologiestack ablÃ¤uft. Vorher habe ich hauptsÃ¤chlich in modernem C++ und Rust Anwendungen entwickelt, bei beiden hatte ich aber relativ hÃ¤ufig das GefÃ¼hl das manche Dinge deutlich aufwendiger waren, als sie sein mÃ¼ssten. Mein Ziel war es ein Umfeld kennenzulernen, in dem die langfristig am wenigsten KomplexitÃ¤t schaffende LÃ¶sung, die ein Problem angemessen lÃ¶st, als die Beste wahrgenommen wird. Da Webentwicklung den Ruf hat einsteigerfreundlich zu sein, und fÃ¼r viele Probleme schon eine vorgefertigte LÃ¶sung zu haben, schien es mir logisch in diesem Bereich nach eine Unternehmen zu suchen, dass mir so ein Umfeld bieten kann.

Ich habe mich am Ende fÃ¼r getpacked entschieden, weil ich bei ihnen den Eindruck hatte, da das reduzieren von KomplexitÃ¤t einen hohen Stellenwert hatten. Ãœberzeugt haben mich vor allem drei Grundsatzentscheidungen die das gut bezeugen. Zum einen, dass das Unternehmen keine eigenen Server anmieten oder betreiben wird, sondern komplett auf serverless SaaS Technologien setzt. Zum anderen, dass keine Smartphone App, sondern nur eine mobiloptimierte Webanwendung entwickelt wird. Ausserdem wird das Projekt Server- und Clientseitig in JavaScript im selben Stil geschrieben. 

Meine Projekte wÃ¤hrend der Praxisphase waren hauptsÃ¤chlich im Softwarengineering Bereich angesiedelt.

Faktenreiche Kurzcharakteristik des Praktikums und der Institution
------------------------------------------------------------------
### Ãœber getpacked
getpacked ist ein Startup das eine Software as a service LÃ¶sung fÃ¼r online Bestellungen anbietet. Der Fokus liegt dabei mehr auf Vorbestellungen zur Abholung, Bestellungen mit Lieferung sind allerdings auch mÃ¶glich. Die Zielgruppe sind hauptsÃ¤chlich HoflÃ¤den, aber auch Gastronomie, BÃ¤ckereien und Metzgereien. Vor allem in den HoflÃ¤den, BÃ¤ckereien und Metzgereien ist es bisher unÃ¼blich gewesen, online Vorbestellungen anzubieten. Gerade bei diesen LÃ¤den ist es aber ein klarer Vorteil Vorbestellungen anzubieten, da es hier StoÃŸzeiten gibt, zu denen deutlich mehr Kunden kommen, als am Rest des Tages. Wenn ein Teil der Kunden allerdings Vorbestellungen aufgibt, kÃ¶nnen diese im Vorraus gepackt und bezahlt werden und die Kunden mÃ¼ssen ihre Bestellung nur noch abholen.

Im FrÃ¼hjahr 2021 wurde die getpacked GmbH offiziell gegrÃ¼ndet, vorher war getpacked ein Teil der 360VIER GmbH. Aktuell hat das Unternehmen 8 Mitarbeiter, von denen 3 in der Entwicklung arbeiten. Die Firma hat rund 100 Kunden die mit getpacked erfolgreich ihre Produkte anbieten. 

### Aufgaben im Praktikum
Meine Aufgaben in der Praxisphase waren hauptsÃ¤chlich die Aufbereitung des Programmcodes und der Entwicklungsinfrastruktur, aber auch viele andere Dinge.

#### EinfÃ¼hrung einer Continuous Integration/ Continuous Delivery Infrastruktur
Mein erstes Projekt bei getpacked war es eine CI/CD pipeline aufzusetzen und einzufÃ¼hren. Wir haben uns dabei fÃ¼r GitLab CI entschieden, da wir GitLab sowieso schon als Softwareentwicklungsplattform eingesetzt haben und wir unseren Technologiestack nicht komplizierter machen wollten, als nÃ¶tig. Da ich vorher schon relativ viel Erfahrung mit verschiedenen CI Programmen gesammelt hatte, ging das aufsetzen von GitLab CI relativ schnell. Was lÃ¤nger gedauert hatte war, die Geschwindigkeit der Builds zu erhÃ¶hen. Da unser Projekt circa 500MB an AbhÃ¤nigkeiten hat, war es keine angebrachte LÃ¶sung diese bei jedem Build erneut herunterzuladen. Die in GitLab CI integrierten Funktionen zum speichern von Artefakten waren bei der Menge auch zu langsam um sinnvoll eingesetzt werden zu kÃ¶nnen. Die LÃ¶sung fÃ¼r das Probblem war es dann bei jeder Ã„nderung der Dependencies einen neuen Container mit allen Dependencies zu erstellen und den fÃ¼r diesen und alle zunkÃ¼nftigen Builds zu benutzen.
Dadurch konnten wir die Deploymentfrequenz von ~3mal pro Woche auf ~4mal pro Tag erhÃ¶hen.

#### Sicherstellung einer hohen Codequalitaet
Eine Aufgabe die durchgehend an der ich durchgehend beschaeftigt war, war die Verbesserung der Codequalitaet. Die Entwicklung bei getpacked wurde oft durch Bugs ausgebremst, die durch klareren Code vermeidbar gewesen waeren. Oft war es allein durch die Betrachtung ihrer Schnittstelle unklar, wie Komponenten verwendet werden, damit sie das tun was man erwartet. Der Code in den Komponenten war allerdings auch oft zu komplex, um schnell zu verstehen, wie sie verwendet werden. Ausserdem war die Formatierung des Quelltexts inkonsistent, und der Zustand der Anwendung war nicht immer klar. Einige Massnahmen zur Sicherstellung einer der Codequalitaet wurden mir anfangs aufgetragen, andere habe ich selbst erarbeitet.

#### Erarbeiten von Guidelines zur Verbesserung der Wartbarkeit
Um die CodequalitÃ¤t auch langfristig hoch zu halten habe ich Guidelines zur Verbesserung der Wartbarkeit erarbeitet.

Die Guidelines sind zum einen Regeln fÃ¼r linter, formatter oder Ã¤hnlichen Programmen die diese automatisiert durchsetzen kÃ¶nnen. In diese Kategorie fallen vor allem
- Statische analyse mit TypeScript
- Statische analyse mit eslint
- Automatische Codeformatierung
- Automatisches verwalten von imports
- Globales CSS verbieten
- Naming conventions fÃ¼r Interfaces und Funktionen
Diese Regeln werden direkt in vscode, beim Speichern, in Precommit-Hooks, oder in CI jobs durchgesetzt, um die CodequalitÃ¤t sicherzustellen

Neben den Dingen die man Ã¼berprÃ¼fen kann gibt es noch einige Faktoren in den Codingstandarts die nicht automatisch Ã¼berprÃ¼ft werden kÃ¶nnen, da sie mehr die Art betreffen wie man Code schreibt und darÃ¼ber nachdenkt. Wir fanden es sinnvoll auch dafÃ¼r Richtlinien festzulegen, damit sich die Codebase auch im Stil einheitlicher anfÃ¼hlt. In diese Kategorie fallen:
- Erst denken, dann programmieren
- Weniger Code meist besser als viel Code ist
- Dinge richtig zu bennenen ist die halbe Miete
- Guard clauses sind die bevorzugte Art von Verzweigungen

#### Umstellen der Codebase auf striktes TypeScript
Eine meiner ersten Aufgaben war es die Codebase der Webanwendung fÃ¼r eine Umstellung von JavaScript auf TypeScript vorzubereiten. Das Team hatte vorher schon angefangen TypeScript im Serverseitigem Code zu verwenden. Dort wurden aber die meisten Funktionen zur starken ÃœberprÃ¼fung der Typen abgestellt, um die Entwicklungsgeschwindigkeit zu erhÃ¶hen, wodurch allerdings auch keine der Vorteile von Typescript genutzt wurden.

##### Was ist TypeScript und wie wollen wir es nutzen
Die Grundidee hinter TypeScript ist, das es normales Javascript mit zusaetzlichen Typinformationen ist, die beim kompiliern erst zur Ueberpruefung der Korrektheit benutzt und dann komplett entfernt werden. Uebrig bleibt normales JavaScript. Als Folge dessen hat TypeScript die Eigenschaft, dass es beim kompilieren komplett statisch getyped ist, bei der Ausfuehrung aber dynamisch. Man kann deshalb in Typescript den Typ einer Variable auch als `any` angeben und damit komplett auf Ueberpruefung der Korrektheit in der Verwendung dieser Variable verzichten. Das fuehrt allerdings zu weniger Klarheit darueber, welche Werte Variablen annehmen koennen. Damit gibt TypeScript die Entscheidung, wie stark Typen ueberprueft werden sollen an die Entwickler.

Die erste Teilaufgabe der Umstellen der Codebase auf TypeScript war es also das zu entscheiden. Dazu habe ich mit allen Teammitgliedern gesprochen um zu verstehen, wie sie dazu stehen. Die Grundhaltung war etwas Angst, dass durch TypeScript die allgemeine Produktivitaet sinkt, da man sich mehr Gedanken darueber machen muss, wie die Schnittstellen von Komponenten aussehen und wie man diese in TypeScript definiert. Allerdings sind genau das auch die Gruende, weshalb wir zu TypeScript wechseln wollten. Klar definierte und gut durchdachte Komponenten sind wesentlich einfacher zu verwenden und wartbarer. Deshalb haben wir uns dazu entschieden TypeScript so strikt wie moeglich einzustellen.

##### Und was habe ich dafuer gemacht
Die zwei groessten Herausforderungen bei der Umstellung auf Typescript waren zum einen herauszufinden was die Typen in existierendem Code sind und sicherzustellen das auch aller zukuenftige Quelltext mit sinnvollen und korrekten Typen versehen ist. 

Beim Herausfinden und Definieren von Typen in existierendem Code habe ich hauptsaechlich darauf gesetzt Annahmen ueber die Typen von Dingen aufzustellen und diese bei Unklarheit dann im Debugger zu verifizieren. Die Annahmen habe ich entweder durch Gespraeche mit den anderen Teammitgliedern oder durch den Kontext des Codes versucht aufzustellen. Meistens war es nicht noetig die Annahmen durch Tests zu ueberpruefen, da wenn alle Orte an denen ein Komponent verwendet wird mit Typen versehen sind, sich der Compiler beschwert, wenn etwas nicht passt.

Nachdem die Kernkomponenten der Codebase mit Typen versehen waren, habe ich sichergestellt, dass auch aller neuer Code in striktem TypeScript geschrieben wird und  das der Rest der Codebase im Laufe der Zeit zu TypeScript wird. Dazu habe ich unter anderem Linterregeln eingefuehrt, die weder die explizite, noch die implizite Verwendung von `any` zu erlauben. Ich mit dem Team einen kurzen Crashkurs gemacht, damit alle ein Verstaendnis dafuer haben, wie und warum wir TypeScript einsetzen. Ausserdem habe ich dafuer gesorgt das Team stetig mit Informationen zum Anteil von TypeScript und JavaScript an der Codebase zu versorgen und es zu feiern, wenn der JavaScript Anteil sinkt.

#### Logik fÃ¼r datenkonsitenz auf Serverseite migrieren
TODO
Da
#### Einarbeiten und verwenden verschiedener mir neuer Technologien

#### Umstellen auf css auf Komponentenebene
Bei normalen css Stylesheets erstellt man global gÃ¼ltige Klassennamen, die auf alle HTML Elemente einer bestimmten Klasse angewandt werden. In Komponentenbasieren Webanwendungen fÃ¼hrt das oft zu Problemen, da wenn mehrere Komponenten den selben Klassennamen verwenden, sie sich dadurch auch oft unbemerkt gegenseitig beinflussen. In getpacked hatten wir zum Beispiel die Klasse `cartButton` die zum einen einen Knopf mit dem Preis des aktuellen Warenkorbs, der diesen auch Ã¶ffnet gestaltet, zum anderen aber auch den Knopf um ein Produkt in den Warenkorb hinzuzufÃ¼gen. Da beide KnÃ¶pfe relativ Ã¤hnlich aussahen, ist nicht aufgefallen, dass beide den die selbe CSS Klasse benutzen, bis wir die Farbe von einem anpassen wollten, was dann aber auch den anderen betroffen hat. Die LÃ¶sung war das Problem war es auf css mdoule umzustellen, dabei sind Klassennamen immer an eine Komponente gebunden. Erreicht wird das dadurch, dass die Namen der CSS Klassen im Buildprozess so modifiziert werden, dass sie einzigartig sind. So wird aus dem `cartButton` in der Basket Komponent zum Beispiel `Basket_cartButton_be8j3`.

#### Performance optimierung eine Webanwendung
Eines meiner Projekte war die Optimierung der Ladezeit der Webseite.
Da getpacked mit React gebaut ist, wurde komplett auf clientseitiges rendering gesetzt. Da die Unterscheidug zwischen verschiedenen Unterseiten (z.B. der Shop fÃ¼r Kunden oder das Admininterface zur verwaltung der Shops) dabei nur Clientseitig erfolgt wurden auf jedet Seite alle Skripte geladen. Ausserdem wird bei clientseitigem rendering erstmal eine leere Webseite qusfeliefert, die dann noch mit Inhalt gefÃ¼llt werden muss, was auch etwas Zeit braucht.
Wir haben verschiedene LÃ¶sungen fÃ¼r diese Probleme geprÃ¼ft und haben uns dann fÃ¼r nextjs entschieden, da es diese beiden Problem relativ automatisch lÃ¶st. 
Ein weiteres Performanceproblem war, dass auf der Seite oft Dinge in mehreren Stufen geladen aus der Datenbank geladen werden mussten. Zum Beispiel mussten im Frontend erst alle Produktgruppen geladen werden, und danach konnten erst die einzelnen Artikel geladen werden, da ihre IDs in den Produktgruppen gespeichert sind.

Wir konnten diese Probleme auf nicht durch vorgenerierte nextjs Seiten lÃ¶sen, da alle angezeigten Daten in echtzeit mit der Datenbank synchronisiert werden, wozu aber eine Verbindung mit der Datenbank bestehen muss, die beim Ãœbergang zwischen server und cliebt logischerweise verloren geht. Meine LÃ²sung fÃ¼r dieses Problem war es einen Cache in die Webseite einzubauen, damit, bis einen Verbindung zu Firestore aufgebaut ist und dir aktuellen Dokumente erhalten werden, schon mÃ¶glicherweise veraltete gecachted Daten angezeigt werden. Bei vorgenerierten Seiten, wird der cache schon serverseitig mit den fÃ¼r die jeweilige Seite relevanten Daten gefÃ¼llt und dann in die vorgenerierte Seite mit eingebaut.
Dadurch sind die vorgenerierten Seiten in allen FÃ¤llen in den sich die Daten in der zwischenzeit nicht verÃ¤ndert haben identisch zu den clienseitig gerenderten Seiten. Damit kann die Webseite schon benutzt werden, sobald sie geladen hat.
Die Ladezeit fÃ¼r eine durchschnittliche Shopseite ist von ~6 Sekunden auf ~0.7 Sekunden gesunken.

#### Wechsel des JavaScript Frameworks
Wenn eine Sache stereotypisch fÃ¼r die Entwicklung von Webanwendungen ist, so ist das die groÃŸe Zahl verschiedener JavaScript Frameworks und das es immer ein neues cooleres Framework gibt. Zu Beginn meiner Praxisphase wurde die Anwendung mit React entwickelt. Mit React wird komplett auf clientseitiges rendering gesetzt, der Webserver gibt also jedem Besucher der Webseite die komplette javascript Anwendung, die dann im Webbrowser die Seite aufbaut. Da das aber in unserem Fall zu teilweise sehr langen Ladezeiten gefÃ¼hrt hat, da die Bestellseite fÃ¼r Kunden und die Adminseite fÃ¼r Ladenbesitzer immer zusammen geladen werden mussten. Ausserdem wirkt sich clientseitiges rendering in der Regel auch negativ auf die Platzierung in den Ergebnissen von Suchmaschinen aus. Einen meiner Aufgaben war es nun eine LÃ¶sung fÃ¼r dieses Problem zu finden und umzusetzen. Ein weiteres Kriterium war es, das die  die Umstellung mit mÃ¶glichst wenig Aufwand verbunden sein sollte. Die Entscheidung fiel auf Next, da es sich dabei im Grunde nur um eine Erweiterung von React mit auftrennung in verschiedene Seiten und serverseitigem rendering handelt. Es gibt bei Next fÃ¼r jede Unterseite der Webanwendung eine eigene React Anwendung, allerdings optimiert Next die ÃœbergÃ¤nge zwischen verschiedenen Unterseiten, sodass diese ohne eine neuladen der Seite clientseitig passieren kÃ¶nnen. AuÃŸerdem wird bei Next jede Unterseite serverseitig einmal vorgerendert und das hierbei erzeugt HTML wird mit der Seite an den Webbrowser geschickt und dient als eine Art Platzhalter, bis das clientseitige rendering abgeschlossen ist.

Die Umstellung der Anwendung auf Next hat etwa einen Monat gedauert, da mit ihr auch eine Umstellung von JavaScript auf TypeScript verbunden war. Da viele Teile das Codes angepasst werden mussten, haben wir beschlossen, dass es einfacher ist alles dabei auf Typescript umzustellen, da man dabei auch die Schnittstellen von Komponenten klar definieren muss. Vorher war es ein Problem, dass oft unklar war was es bewirkt, wenn man eine Eigenschaft auf einem Komponenten setzt und ob die Ã¼berhaupt verwendet wird. Zum Beispiel gab es viele Situationen in denen Komponenten Eigenschaften mitgegeben wurden, die es inzwischen garnicht mehr gibt.

Der erste Teil der Migration zu Next war es die Anwendung von einer Seite in mehrere Teilseiten aufzutrennen. Da wir vorher ddie Entscheidung welche Seite angezeigt werden soll auch schon auf Basis der URL getroffen haben, hatten wir schon Reactkomponenten fÃ¼r die meisten Seiten. Dadurch war das auftrennen in Nextjs Seiten relativ einfach. Da ich allerdings dabei die Dateien auch auf TypeScript portiert haben hat das auftrennen auch ungefÃ¤hr eine Woche gedauert.

Der GroÃŸteil der Arbeit der Umstellung auf nextjs war es sicherzustellen, das jede Unterseite auch erfolgreich Serverseitig rendered. Das Hauptproblem dabei ist, dass man auf die Informationen die nur im Browser des Nutzers verfÃ¼gbar sind, serverseitig keinen Zugriff hat. Das umfasst unter anderem BildschirmgrÃ¶ÃŸe, Cookies, Localstorage und Zugriff auf DOM Elemente. Deshalb mussten wir alle Stellen finden an denen das passierte und jeweils eine individuelle LÃ¶sung finden, wie man damit umgeht.

NextJS hat integrierte LÃ¶sungen fÃ¼r einige Probleme fÃ¼r die wir vorher andere Libraries verwendet haben. Zum Beispiel kann NextJS Bilder selbst serverseitig skalieren und dadurch Bilder nur in der benÃ¶tigten GrÃ¶ÃŸe auslieferen. Damit das funktioniert musste ich alle Bilder auf die NextJS Image Komponente umstellen.

#### Gitlab CI pipeline optimieren
Am Anfang meines Praktikum hatte ich Gitlab CI aufgesetzt. Die CI war so konfiguriert, dass jeder Branch der auf den `main` Branch gemerged werden soll erst die CI tests erfolgreich durchlaufen muss. Mit der Zeit hat sich allerdings herausgestellt, dass das unsere Entwicklungsgeschwindigkeit ein wenig ausbremst. Wenn man erst 10 Minuten warten muss, bis die Pipeline durchgelaufen ist. Meine Aufgabe war es dann auszuwerten, warum die Pipelines so lange brauchen. Der Hauptgrund war, dass die von Gitlab gehosteten Jobrunner den Dockercontainer in dem die Tests ausgefÃ¼hrt wurden fÃ¼r jeden Schritt immer wieder neu herunterladen mussten, da fÃ¼r jeden Schritt ein anderer Runner verwended wird.

Die LÃ¶sung fÃ¼r das Problem ist es in der Regel eigene Runner zu hosten, die die Dockerimages lokal vorhalten, sobald sie einmal heruntergeladen wurden. Eigene Runner auf Servern zu hosten kam fÃ¼r uns allerdings nicht in Frage, da schnelle Server doch relativ teuer sind. Gitlab bietet zwar die MÃ¶glichkeit ein Kubernetes Cluster anzubinden und darauf dann bei Bedarf Runner zu erschaffen. Der administrativa Aufwand wÃ¤re allerdings ziemlich hoch gewesen und es hÃ¤tte unsere Probleme auch nicht komplett gelÃ¶st, da Kubernetes auch immer mindestens einen aktiven Server braucht, der Kosten verursacht.

Als nÃ¤chstes hatte ich versucht, ob es sinnvoll mÃ¶glich ist, die Runner lokal auf den Computern der Entwickler laufen zu lassen. Den Runner auszufÃ¼hren war Ã¼berraschend unkompliziert, da er als docker container verfÃ¼gbar ist. Die Kopplung mit Gitlab war auch einfach zu lÃ¶sen, dabei wird beim Starten des Runners nur ein Token fÃ¼r das Projekt benÃ¶tigt, das wir auf dem selben Kanal wie unsere restlichen secrets verteilen kÃ¶nnen. Das letzte Problem war noch das die Runner automatisch gestartet werden. Meine erste Idee war es dazu den Runner beim starten der Anwendung im Debug modus automatisch mitzustarten. Das hatte allerdings den Nachteil, dass die Runner immer gestartet wurden, auch wenn man es nicht wollte (z.B. weil man wusste, das man gleich offline geht). Ausserdem war es schwer mÃ¶glich herauszufinden, wann der Runner beendet werden sollte. Nach etwas Recherche habe ich herausgefunden, dass vscode eine integrierte Funktion hat, um den Nutzer beim Ã–ffnen eines Projekts zu fragen, ob ein bestimmter Task ausgefÃ¼hrt werden soll. Den Runner darÃ¼ber zu starten hat den Vorteil, dass der Entwickler nichts machen muss auÃŸer das Popup zu bestÃ¤tigen und der Runner auch wieder beendet wird, sobald man fÃ¼r den Tag fertig entwickelt hat.

Dadurch haben wir Runner auf Computern mit Desktop CPUs, die fÃ¼r unsere hauptsÃ¤chlich nicht parallel ausgefÃ¼hrten Jobs ein ganzes StÃ¼ck schneller sind als Server CPUs. Der einzige Nachteil ist, dass Jobs manchmal fehlschlagen kÃ¶nnen, weil ein Entwickler seinen Computer ausschaltet wÃ¤hrend der Job dort ausgefÃ¼hrt wird. In der Praxis ist das aber nur knapp ein mal pro Monat passiert. Mit dieser LÃ¶sung konnte ich ohne mehrkosten zu verursachen die Dauer unserer Pipelines von 7-10 auf 1-4 Minuten zu reduzieren (je nachdem ob noch Container geladen werden mÃ¼ssen und wie viele Runner online sind). 

#### Andere Aufgaben
AuÃŸerdem habe ich wÃ¤hrend meiner Zeit bei getpacked noch ein paar andere Dinge getan:
- Automatisieren von vercel deploys
- Aufsetzen von firestore emulatoren
- Versuch des etablieren von End-To-End Tests mit testcafe
- Aufsetzen von Sentry zum Fehlertracking

Reflexion
---------

### Welche Ziele habe ich mir im praktium gesetzt
Im Praktikum hatte ich mehrere Ziele und Aufgaben, vor allem wollte ich die Codebase und alles drumherum aufrÃ¤umen und strukturieren, und dafÃ¼r sorgen dass sie auch sauber bleibt. Ein weiteres Aufgabe war es eine Such und Ãœbersichtsseite fÃ¼r alle Betriebe in getpacked zu erstellen. Ausserdem hab ich mir selbst das Ziel gesetzt, nachhaltig zu lernen, wie man mÃ¶glichst effektiv moderne Webanwendungen baut. Dazu wollte ich mir anschauen, was es aktuell fÃ¼r Werkzeuge gibt, um effektiver programmieren zu kÃ¶nnen.

### Ziele erfÃ¼llt:
#### AufrÃ¤umen und strukturieren
Ich glaube ich konnte wÃ¤hrend meiner Zeit bei getpacked die Lesbarkeit und Wartbarkeit des Programms deutlich verbessern. Was ich in der Zeit besonders geschÃ¤tzt habe, war das ich relativ viel Zeit in Dinge investieren durfte, die nicht direkt Features fÃ¼r das Produkt bringen, sondern nur langfristig die Geschwindigkeit mit der neue Dinge entwickelt werden kÃ¶nnen erhÃ¶hen. Ausserdem fand ich es cool, dass nahezu alle meiner Bestrebungen in die Richtungen auch von meinen Kollegen angenommen wurden. (Nur das entfernen von unbenutzten imports beim speichern ist auf Wiederstand gestossen).

TODO
- Noch irgendwie erwÃ¤hnen, dass das schon irgendwie eins meiner Ziele von anfang an war, ich hab afaik sogar im VorstellungsgesprÃ¤ch verlangt, dass ich 1 woche im Monat komplett auf refactoring setzen darf.

#### Lernen von Webentwicklung
Webentwicklung mit React ist jetzt auch eine der Sachen die ich kann. Was mich Ã¼berrascht hat, war es zu sehen, wie einfach man mit moderenen Frameworks/Tools komplexe UIs strukturien kann. Vorher hatte ich hauptsÃ¤chlich mit Qt gearbeitet, dabei kam mir das erstellen von UIs immer unnÃ¶tig aufwÃ¤ndig vor, ich hatte aber akzeptiert, dass es wahrscheinlich nicht viel einfacher geht. Ausserdem kann ich jetzt JavaScript, was auch nÃ¼tzlich ist.

#### Werkzeuge ausprobieen
WÃ¤hrend dem Praktikum konnte ich viele Werkzeuge ausprobieren. Teilweise kannte ich einige davon schon vorher und hatte nur noch keine Chance sie in der Praxis zu verwenden. Andere haben aber auch erst wÃ¤hrend der Praxisphase durch meine Kollegen meine Aufmerksamkeit gewonnen.
Von Anfang wollte ich KI basierte automatische VervollstÃ¤ndigung  verwenden. Anfangs habe ich dazu tabnine benutzt, dann hatte ich die MÃ¶glichkeit GitHub Copilot einzusetzen und bin dann auch dabei geblieben, weil Copilot deutlich besser VorschlÃ¤ge macht.
Mit GitLab CI wollte ich auch ein weiteres CI tool kennenlernen und das hat auch funktioniert.

Ein weiteres Werkzeug das ich zu schÃ¤tzen gelernt habe, war der nix package manager, mit dem es ziemlich einfach mÃ¶glich ist auf allen Computern in der selben Umgebung zu entwicklen. Wir hatten anfangs ab und an Probleme damit, dass jeder andere Versionen von verschiedenen Programmen installiert hatte. Mit nix konnten wir das nachhaltig lÃ¶sen.

Ausserdem habe ich wÃ¤hrend meiner Zeit in der Praxisphase angefangen viel mit gitpod zu arbeiten. Dabei handelt es sich im Grunde um vscode, aber es lÃ¤uft komplett im Browser. Vorallem bei Codereviews hat das den Prozess enorm beschleunigt, da man mit einem Klick auf dem Pullrequest direkt eine IDE mit den zu reviewenden Ã„nderungen hat.

Auch etwas, dass ich vor der Praxisphase Ã¼berhaupt nicht auf dem Schirm hatte waren nocode workflow automation Programme, bei denen man verschiedene APIs relativ unkompliziert grafisch ansteuern kann. Die sind Ã¼berraschend praktisch, wenn man einfach nur zwei Dinge schnell verbinden will, aber dafÃ¼r nicht extra einen Server aufsetzen mÃ¶chte. Wir konnten es damit zum Beispiel relativ unkompliziert umsetzen, dass bei jeder neuen Bestellung eine Nachricht darÃ¼ber in einen Slack Channel gesendet wird.

### Herausforderungen
Die wohl grÃ¤
- anfangs Diskussionen Ã¼ber GeschÃ¤ftsmodell, aber irgendwann ignoriert, weil nicht im Aufgabenbereich 
- Web-Entwicklung, weil noch nie vorher gemacht; aber gut geklappt, weil Programmieren an sich schon bekannt + Google -> hat gereicht; selbst aufs Projekt bezogen beigebracht -> Projekt bzw Praktikum in dem Bereich hat geholfen, dass Web-Entwicklung jetzt deutlich routinierter und kompetenter (alle MÃ¶glichkeiten bekannt) ablaufen wÃ¼rde; 


## Irgendwas anders machen?
Idee mit Geschwindigkeit hinschreiben und dann quasi Argumente dagegen ðŸ˜Š
- weniger Wert auf guten Code, mehr auf Geschwindigkeit? Weil: Firma jetzt pleite! Langfristig schneller durch guten Code jetzt irrelevant. ABER: Konnte man da nicht wissen -> nÃ¤chstes Mal vielleicht anderen Fokus legenâ€¦? Entspricht aber nicht unbedingt eigenen Werten, deshalb wenn dann Fokus nur in Absprache mit Firma/Vorgesetzten verschieben (SOLL es spÃ¤ter wiederverwendbar/anpassbar bleiben?) 
Also eigentlich nÃ¶. Weil konnte man nicht wissen. Und so mehr bei gelernt! Also gerade fÃ¼r als Praktikum richtig so gewesen.

### HÃ¶hepunkte
#### Arbeiten in einem coolen Team
An dem Praktikum hat mir besonders gefallen mit Leuten die aus so einer Startup Blase kommen zu arbeiten. Im Vergleich zu meiner vorherigen Arbeitserfahrung waren alle viel motivierter etwas cooles zu bauen und dabei auch noch SpaÃŸ zu haben. AuÃŸerdem wurde viel Wert auf gute Kommunikation gelegt was mir auch sehr gefallen hat. Wir hatten zum Beispiel immer eine guten Ãœberblick darÃ¼ber wer gerade was macht und wenn sich herausgestellt hat das jemand anders schon Erfahrung mit einem Thema hatte konnte man das dann einfach schnell zusammen bearbeiten. Was ich auch cool fand war das sich niemand zu fein war um Hilfe zu fragen, so hab ich wahrscheinlich Ã¤hnlich viel Hilfe gegeben wie bekommen. Arbeit in so einem offenen Team war fÃ¼r mich eine neue Erfahrung, gerne wieder.

#### Inhaltliche Hoehepunkte
TODO
- automatische Fehlererkennung, dass nicht nur abstÃ¼rzt oder so, sondern stattdessen automatische Nachricht. Einmal die Nachricht Ã¼ber ne fehlgeschlagene EBstellung, bei der Paypal kaputt war -> in wenigen Minuten behoben und ohne Kundenkontakt rechtzeitig fÃ¼r 3. Versuch des Kunden gelÃ¶st! 
Hier kam AufrÃ¤umen -> Anpassung mit besserer Geschwindigkeit mit Fehlererkennung zusammen -> Hat alles geklappt! Hatte Sinn

### Was kann ich besonders gut im Vergleich?
TODO
selbststÃ¤ndig arbeiten (Aufgaben selbst suchen bei nur sehr losen Erwartungen)
Sich Sachen selbst ergooglen (eigenstÃ¤ndig LÃ¶sungen fÃ¼r Probleme finden, ohne Anleitung) ProblemlÃ¶se-Kompetenz
viele MÃ¶glichkeiten mit den automatischen Sachen und so waren dem Team nicht bekannt, aber Dir schon -> durchs ErklÃ¤ren hat sich das alles gefestigt

### Was halte ich fÃ¼r meine SchwÃ¤chen und Grenzen?
#### Zeitplanung
Ich habe bei getpacked gelernt, dass ich mir relativ schwer damit tue realistisch einzuschÃ¤tzen, wie lange ich fÃ¼r Dinge brauchen werde. Es ist mir relativ hÃ¤ufig passiert, dass ich Aufgaben gnadenlos unterschÃ¤tzt habe, und sie in RealitÃ¤t deutlich lÃ¤nger gedauert haben. Ich fÃ¼hle mich dann oft schlecht, wenn irgendwie alles hinter dem Zeitplan liegt. Ich glaube das das Hauptproblem ist, dass ich bei der EinschÃ¤tzung von Zeiten meistens davon ausgehe, dass alles direkt gut funktioniert, aber dann bei der DurchfÃ¼hrung dann oft unvorhergesehene Hindernisse auftauchen. In Zunkunft werde ich versuchen prinzipiell Aufgaben mit einem groÃŸzÃ¼gigen Zeitpuffer zu planen, wenn es schneller geht ist, ist es dann eine positive Erfahrung und wenn nicht ist es auch ok.

#### Ich tendiere dazu mich in subjektiven Diskussionen festzufahren
Es ist mir besonders gegen Anfang oft passiert, dass ich mich dazu verleiten lassen Ã¼bermÃ¤ssig viel Zeit und Energie in eigentlich relativ sinnlose Diskussionen zu stecken. Eins der extremsten Beispiel war die Diskussion darÃ¼ber, wie der Knopf zum anmelden mit Email und Password im Kontrast zur den KnÃ¶pfen zur Anmeldung mit third-party Authentication Providern dargestellt werden soll, sodass mÃ¶glichst wenige Nutzer eine Anmeldung mit Email und Passwort wÃ¤hlen. In den GesprÃ¤chen hatte niemand Daten darÃ¼ber wie sich die Gestaltung des Knopfes tatsÃ¤chliche auf das AnmeldeverhÃ¤ltnis auswirkt. Alle waren sich auch einig, dass es wahrscheinlcih keinen groÃŸen Unterschied macht, welche der beiden trivialen LÃ¶sungen wir wÃ¤hlen. Realistisch gesehen haben wir zwei Stunden ohne Grundlage Ã¼ber ein sinnloses Thema diskutiert. Inzwischen akzeptiere ich bei solchen Diskussionen einfach irgendeine LÃ¶sung, da sie zu dem Zeitpunkt gleichwertig sind. Wenn sich dann herausstellt, dass die Wahl falsch war, kann man immernoch mehr Daten darÃ¼ber sammeln und dann spÃ¤ter nochmal beide AnsÃ¤tze sinnvoll vergleichen. Im Praktikum habe ich gelernt, zu erkennen, wenn ich mich in so einer Situation befinde und diese dann zu verlassen.

#### Reden mit Leuten die ich nicht gut einschÃ¤tzen kann
Wenn ich mit Leuten reden muss, die ich nicht gut einschÃ¤tzen kann, fÃ¼hle ich mich meistens sehr unsicher. Weil ich nicht genau weiss wie ich mich verhalten soll um nicht zu seltsam zu wirken. Das scheint allerdings grÃ¶ÃŸtenteils ein Problem zu sein, das nur in meinem Kopf stattfindet, da ich nie das Feedback bekommen habe, dass ich da tatsÃ¤chlich seltsam gewirkt habe. Nachdem ich ein paar mal mit jemandem Kontakt hatte legt sich das aber in der Regel und ich fÃ¼hle mich sicherer. Auch wenn ich mir solche Situationen unangenehm sind, habe ich festgestellt, dass es mir auch irgendwie SpaÃŸ macht in solchen Situationen zu sein.

## Neu gelernt:
TODO: Maybe remove
- Manche Diskussionen nicht anzetteln, sondern die Aufgaben einfach erledigen, wie es einem gesagt wurde (sozialer Bereich)

### Von andern eingeschÃ¤tzt: s. Brief vom Chef
TODO: Maybe remove
Vergleich s. StÃ¤rken und SchwÃ¤chen von oben im Vergleich zum Chef-Brief


### Fazit

#### Aufgaben waren sehr eigenverantwortlich gesucht, hat Dir aber gelegen ðŸ˜Š -> gute Passung: Freiheit vom Team aus, dass Eigenverantwortung mÃ¶glich 
Alle Ziele erreicht, also erfolgreiches Praktikum. 
Jetzt Arbeitsstelle bei was, was damit zusammenhÃ¤ngt -> Coole MÃ¶glichkeit
